\chapter{Implementation}

	This chapter delves into the implementation of key components that form the backbone of communication with the generator microservice, 
	which is responsible for handling model generation requests in Refinery's architecture.

	First I'll introduce the starting point of the project.
	Then I'll go into detail about how the backend creates a client, which communicates with the generator microservice. Finally I'll go into detail
	regarding the inner workings of the generator server.

	\section{Starting point}
		First, I will introduce the starting point of the project, so we get an overview, of how the backend initially worked regarding the model
		generations.

		The PushServiceDispatcher is the class responsibly for calling the functions of the ModelGenerationService instance, and thus initiating
		the generation related methods.

		\subsection{ModelGenerationService}
			The \textit{ModelGenerationService} is a core component of the application, designed to handle the initiation and management of
			model generation tasks on the backend server. This class encapsulates the logic for coordinating the execution of these 
			tasks, while providing a seamless interface for both initiating and canceling model generation processes.
			It is a singleton class, so from a generator point of view, we might consider this class to be the real dispatcher.

			The key features and responsibilities of the class include:
			\begin{itemize}
				\item{\textbf{Service Initialization:}} The \textit{ModelGenerationService} is a singleton, 
				ensuring a single, consistent instance throughout the application's lifecycle.
				It retrieves configuration parameters such as the model generation timeout 
				from the environment, defaulting to 600 seconds if not explicitly set.
				\item{\textbf{Model Generation Workflow:}} The main responsibility of the service is to execute model generation requests 
				by instantiating workers (\textit{ModelGenerationWorker}), using multithreading. 
				The workers perform the actual computational tasks:
				\begin{enumerate}
					\item The generateModel method is provided the PushWebDocumentAccess instance, which holds the model described by the partial modeling language
					of Refinery.
					\item A ModelGenerationWorker is instantiated and configured with the document state (provided by the PushWebDocumentAccess), 
					a random seed and a timeout value.
					\item The worker is started, as well as the resource heavy generation process. 
					The worker is started on a background thread. 
					The thread pool of for the generation workers can be configured via the 
					\textit{REFINERY\_MODEL\_GENERATION\_THREAD\_COUNT} environment variable.
				\end{enumerate}
				\item{\textbf{Cancellation Mechanism:}}
				During this process listed above, the service interacts with the document’s \textit{ModelGenerationManager} to monitor the worker's activity.
				The timeout and cancellation is handled via the use of cancelation tokens.
			\end{itemize}
			The use of dependency injection for worker provisioning ensures that the service is decoupled from the specific implementation details of task execution, making it easier to extend or modify in the future.

		\subsection{ModelGenerationWorker}
			The \textit{ModelGenerationWorker} class is the backbone of the backend’s model generation process. 
			It encapsulates the logic to handle the generation of computational models using a multithreaded approach, 
			ensuring responsiveness and reliability during execution. 
			Each instance of this class operates independently to process a specific model generation request.	

			The key features of the class include thread-safe execution, error management, scalable design via the use of the ExecutorService
			and the thread pool based multithreaded execution that it offers.

			The main responsibilites of the class are:
			\begin{itemize}
				\item{\textbf{Task Management:}} Each worker is uniquely identified by a UUID, allowing precise tracking and management of tasks.
				The worker implements the Runnable interface, enabling it to be executed as a separate thread in a thread pool.
				\item{\textbf{State Configuration:}} The worker’s state is set before execution via the setState method. This method configures the input document (PushWebDocument), random seed, and timeout duration required for the model generation process.
				The input text is extracted from the document and forms the basis of the model generation workflow.
				\item{\textbf{Model Generation Execution:}} The run method drives the core workflow. It first initializes a timeout mechanism and notifies the system that model generation has begun.
				The doRun method carries out the actual model generation, leveraging the following components:
				\begin{itemize}
					\item {\textbf{ProblemLoader:}} Parses the input text into a formal problem representation.
					\item {\textbf{ModelGenerator:}} Creates a generator instance to process the problem and produce a solution.
					\item {\textbf{MetadataCreator:}} Extracts metadata (nodes and relations) from the generated model for further processing.
					\item {\textbf{PartialInterpretation2Json:}} Converts intermediate results into a JSON format for downstream tasks.
				\end{itemize}
				\item{\textbf{Result Notification:}} Once a model is successfully generated, or if an error occurs, the worker notifies the document's precomputation listeners with the result. This ensures that other system components are informed of the status of the generation process.
				\item{\textbf{Cancellation Handling:}} The worker supports graceful cancellation through the cancel method. It uses a CancellationToken to periodically check whether the operation has been canceled and interrupts execution if necessary.
				A timeout mechanism automatically cancels the task if it exceeds the configured duration, ensuring that no worker consumes resources indefinitely.
			\end{itemize}

			The ModelGenerationWorker is the enabler of backend-driven computation.
			This implementation effectively delegates computationally intensive tasks, trying to minimize 
			the burden on client communication.

		\textbf{TODO!!! INSERT AN IMAGE OF AN UML DIAGRAM OF THE STARTING APPLICATION}

	\section{Generator Client}
			Now that the deployed implementation has been been described, we can restructure our application, so that the 
			model generation is done via the generation microservice.

			The design of the \textit{ModelGenerationService} is scalable and modular:
			By delegating the actual computation to workers (ModelGenerationWorker), the service separates orchestration from execution, 
			allowing for future modifications. 
			
			This comes in handy, when implementing our client for communication with
			the generator server. We have to implement a client, which communicates generation requests towards the generator server,
			and upon completion, receives such generation results.

			\subsection{GeneratorWebSocketEndpoint}
			The client-side component responsible for sending generation requests and handling responses is implemented as the GeneratorWebSocketEndpoint class,
			leveraging Jetty's WebSocket API. This endpoint facilitates asynchronous communication with the generator microservice, 
			ensuring efficient request management over WebSocket connections. 

			In this section, I'll try to describe the key responsibilities and functionalities of the GeneratorWebSocketEndpoint class.
			\subsubsection{WebSocket Configuration} 
				The server, which the client is communicating with, can be configured.
				\begin{itemize}
					\item The WebSocket URI is dynamically determined based on environment variables (\textit{REFINERY\_GENERATOR\_WS\_HOST} 
					and \textit{REFINERY\_GENERATOR\_WS\_PORT}). If these are unset, default values (localhost and 1314) are used to ensure flexibility during deployment.
					\item The constructor initializes a WebSocketClient instance and sets default values, such as the worker's UUID and timeout duration.
				\end{itemize} 
			\subsubsection{Communication towards the server} 
				\begin{itemize}
					\item The client connects to the server via a ClientUpgradeRequest. The connection includes a custom header for the UUID of the worker.
					\item Sending the generation requests via sendGenerationRequest method. The method sends a structured JSON payload containing the request type,
					the UUID, the problem description, and a random seed. This start the model generation process on the server
					\item Sending generation cancel requests via the sendCancelRequest method. This client sends a JSON, with the UUID of the generation to be 
					executed. Each generation opens a new session, with a new UUID for the server, so they can be uniquely idenfitied.
				\end{itemize} 
			\subsubsection{Receiving from the server} 
				Responses from the server are handled by the onText method, which processes various types of messages 
				(result, error, nodesMetadata, relationsMetadata, partialInterpretation), parsing them into appropriate data 
				structures and queuing them for consumption in their appropiate result queues.

			\subsubsection{Parsing responses from the queue} 
				The client maintains several LinkedBlockingQueue instances to manage received data:
				\begin{itemize}
					\item responseQueue: Stores results or errors associated with the generation process.
					\item nodesMetaDataQueue: Holds metadata about nodes in the generated model.
					\item relationsMetadataQueue: Queues relation metadata details.
					\item partialInterpretationQueue: Handles intermediate model interpretation data.
				\end{itemize} 
				The queues are accessed with timeout constraints to prevent indefinite blocking during retrieval. The timeout is set up by the class'
				timeout variable. 
				
				The LinkedBlockingQueue allowed the Jetty API's @WebSocketText annotated onText method, to put the received generation
				results into the queue, while the client is waiting for the results to arrive from the server. As soon as an element is put into the queue
				it can be popped from it. This way our code is safely waiting for the results
				to arrive from the server and no concurrency issues can arise. As I have already mentioned, each generation request instantiates a new
				client, so the size of these queues can only be between 0 and 1. No other generation client is accessing these queues of the instances.

			\subsubsection{Error Handling and Resource Management}
				\begin{itemize}
					\item The WebSocket lifecycle events (onOpen, onClose, onError) are implemented to handle connection state changes gracefully.
					\item Proper resource cleanup is ensured through the close method, which terminates the WebSocket session and stops the client instance.
					In normal operation, the client is the one initiating the closing of the connection.
					\item Errors during critical operations, such as connection establishment or closure, are logged and propagated as exceptions.
				\end{itemize} 

			\subsubsection{Scalability and Extensibility} 
				The GeneratorWebSocketEndpoint class is designed to support scalability.
				\begin{itemize}
					\item The GeneratorWebSocketEndpoint class is designed to support scalability.
					\item Its queuing mechanism ensures thread-safe handling of concurrent operations.
					\item The dynamic configuration allows seamless deployment in different environments without hardcoding server details.
					\item The modular structure facilitates extending the client to handle additional message types or features in the future.
				\end{itemize} 

			This implementation forms the core communication layer between the client and the generator microservice, enabling efficient 
			request handling, response parsing, and error management in a scalable and extensible manner.


		\subsection{ModelRemoteGenerationWorker}
			\subsubsection{Core functionality}
				The ModelRemoteGenerationWorker manages remote model generation tasks by leveraging a WebSocket client (GeneratorWebSocketEndpoint). 
				It sends model generation requests to a remote service, handles server responses, and retrieves metadata and interpretations required 
				for completing the generation process.
				By offloading the generation task to a remote service, this class allows the backend to handle computationally expensive operations 
				efficiently without overloading local resources. It preserves core mechanisms, such as timeout handling, task cancellation, 
				and error reporting, ensuring a robust and reliable workflow.

			\subsubsection{IGenerationWorker}
				For implementation, the IGenerationWorker interface was created, which defines a unified API for all generation workers. 
				This interface standardizes the core operations, including task initialization, execution, timeout management, and cancellation.
				This abstraction ensures that the backend can switch between local and remote workers without altering its core functionality.

				The key methods from the interface include:
				\begin{itemize}
					\item setState: Configures the worker with the input document, random seed, and timeout settings.
					\item start and startTimeout: Enqueues the worker for execution and schedules a timeout to enforce task completion within a defined duration.
					\item doRun: Executes the remote model generation logic by communicating with the external service.
					\item cancel: Cancels the task, ensuring both local and remote operations are halted gracefully.
				\end{itemize}

				The interface is a reusable API, which both the old ModelGenerationWorker, and our newly created ModelRemoteGenerationWorker implement.
				The implementation of this interface grants us plug-and-play functionality. The usage of the new generator microservice is interchangable
				with the old implementation. The backend can use either worker, based on the initial configuration, which can be set by an environment
				variable.
				The interface also allows for future workers to be implemented or a future hybrid functionality.

			\subsubsection{Workflow}
				The execution process of ModelRemoteGenerationWorker begins with setup and state configuration. 

				During task execution, the worker sends a generation request to the remote service by using a WebSocket client instance (GeneratorWebSocketEndpoint). 
				The server's responses are processed incrementally.

				The task completes successfully upon retrieving all necessary results, or it is terminated on errors, cancellation, or timeout.

				Timeouts and cancellations are managed via a ScheduledExecutorService, ensuring that the system remains responsive and resources are freed promptly. In case of errors, the worker captures exceptions, logs the issues, and notifies the backend with appropriate error results.

				The interaction between the GeneratorWebSocketEndpoint and the ModelRemoteGenerationWorker 
				showcases how client-side operations and backend service orchestration are seamlessly integrated to ensure efficient, scalable, and reliable processing.
				The 

			\subsubsection{Impact}
				By integrating remote model generation, this implementation reduces the computational load on the backend server, 
				making the system more scalable. The use of the IGenerationWorker interface allows a modular design, enabling seamless 
				transition between local and remote workers or future extensions. 
				
				Furthermore, this approach demonstrates how backend systems can leverage external services without significant architectural changes, 
				ensuring flexibility and scalability in modern distributed systems.

	\section{Generator Server}
		Now that the client side of the generation process has been introduced, the server side implementation is what should be described next.
		The main idea behind this implementation, was to take the experiences of the local model generation worker, and basically implement everything that 
		is necessary for a generation to happen, in a multithreaded way, on our microservice. It is basically the implementation of the ModelGenerationWorker
		on a separate server.

		\subsection{GeneratorServerEndpoint}
			The GeneratorServerEndpoint is a WebSocket server endpoint that facilitates communication between remote clients 
			and the backend for model generation requests. This class plays a crucial role in enabling real-time, 
			bidirectional communication, supporting features like generation request handling, cancellation, and client disconnection.

			\subsubsection{Core Functionality}
				The two most important functionalities of the class are the handling of the generation requests and cancelation requests, which are
				 received over the 
				WebSocket sessions. 
				
				When a message of type "generationRequest" is received, the endpoint extracts generation details 
				such as the unique identifier (uuid), random seed, and problem description. The data is sent by the client via JSON, so extracting the
				needed key-value pairs is pretty straighforward. These are then forwarded to the ModelGeneratorDispatcher, 
				which manages the actual model generation task.

				For "cancel" messages, the endpoint instructs the ModelGeneratorDispatcher to cancel an ongoing generation task associated with the provided uuid.

				Any errors during the WebSocket communication are captured, logged.

				When a WebSocket session is closed, the endpoint notifies the ModelGeneratorDispatcher to clean up resources associated with the disconnected client.

			\subsubsection{Integration into the workflow}
				The GeneratorServerEndpoint serves as the entry point for remote clients into the backend's model generation system. 
				It relies on the ModelGeneratorDispatcher to manage generation and cancellation tasks. This provides a clean separation of concerns. 
				The design ensures that the endpoint focuses solely on communication, while the dispatcher handles the generation tasks.

			\subsubsection{Scalability and Extensibility}
				This WebSocket-based implementation allows the backend to support multiple concurrent client connections efficiently. 
				By using asynchronous communication, it ensures that tasks are queued and processed without blocking the ongoing generations. 
				The modular design makes it easy to extend functionality, such as adding new message types or enhancing error handling mechanisms.


		\subsection{ModelGeneratorDispatcher}
			The ModelGeneratorDispatcher is a singleton class designed to manage and execute model generation requests on separate threads. 
			Its primary role is to coordinate the model generation tasks, making sure that they run concurrently and their status updates and results are 
			communicated back to clients over open WebSocket sessions. This dispatcher simplifies the handling of multiple requests 
			and helps with maintaining system consistency.

			\subsubsection{Key features}
			The class implements the singleton design pattern to guarantee that only one instance of ModelGeneratorDispatcher exists throughout the application. 
			This is achieved via the use of a private constructor which prevents instantiation of the class from the outside, ensuring 
			that all interactions go through the singleton instance.
			This provides centralized control and avoids conflicting task management.


			Each model generation request is executed in a separate thread to prevent blocking the main application flow. 
			This is achieved through the ModelGeneratorExecutor class, which handles the task logic.
			The running model generations (ModelGenerationExecutor) are stored in a hashmap. The threads are identified by the UUID of the 
			generation (key).

			New generation requests are created, initialized and started on separate threads. They are then added to the previously mentioned hashmap.

			Ongoing tasks can be cancelled via the UUID of the generation. As the hashmap stores these generation tasks identified by their UUID, it is fairly easy to do.

			Once a client has disconnected, the belonging task is cancelled, if not finished yet. The said task is removed from the hashmap. The UUID identification is 
			useful here aswell.

			The main methods of the class are:
			\begin{itemize}
				\item \textbf{getInstance:} Provides global access to the singleton instance of the dispatcher. Ensures thread-safe initialization using synchronized access.
				\item \textbf{addGenerationRequest:} First, dependencies are injected and a new ModelGeneratorExecutor is created for the request.
				Then the executor is initialized with task-specific details such as the random seed, problem string, and the WebSocket session with the client.
				Last, the executor thread is started and gets stored in the threadPool hashmap.
				\item \textbf{cancelGenerationRequest:} Retrieves the executor from the hashmap, based on the parameter UUID. Then the executor is signaled to
				cancel its operation.
				\item \textbf{disconnect:} Removes the executor from the threadPool and calls its disconnect method to release resources safely.
			\end{itemize}

		\subsection{ModelGeneratorExecutor}
		The ModelGeneratorExecutor is a class responsible for performing the actual model generation tasks. It runs on a separate thread, 
		making it suitable for concurrent processing. This class does pretty much what the original ModelGenerationWorker did. 
		It even operates as part of a dispatcher system, executing generation tasks handed over by the ModelGeneratorDispatcher.

		\subsubsection{Key features and responsibilities}
			The main responsibilites of the class are the following:
			\begin{itemize}
				\item \textbf{Initialization:} Before starting, it initializes the problem by loading the problem description, random seed, and WebSocket session details. These were
				received by the GeneratorServerEndpoint over WebSocket, and are given to an executor object by the ModelGeneratorDispatcher.
				\item \textbf{Task Execution (in run()):} The class handles the execution of the model generation. This is done in the exact same way, as it was done previously at the local ModelGenerationWorker.
				\item \textbf{Client communication:} By getting an open WebSocket session, the class instance can send generation state results, metadata and errors to the clients.
				\item \textbf{Cancellation support:} The task can be interrupted or canceled at any point, ensuring that unnecessary processing is avoided. This is especially useful for timeout scenarios or user-initiated cancellations.
			\end{itemize}
			The key features of the class are:
			\begin{itemize}
				\item \textbf{Decoupled Execution:} Each ModelGeneratorExecutor instance works independently, processing a single request and reporting its status without interference from other tasks.
				\item \textbf{Feedback to the clients:} Task status updates are sent back to the dispatcher via the WebSocket session, ensuring real-time communication with clients.
				\item \textbf{Error Handling:} Any issues during validation or model generation are gracefully handled, with appropriate error messages sent to clients.
			\end{itemize}

		\subsection{ServerLauncher}
		The ServerLauncher class serves as the entry point for starting a WebSocket server that 
		processes model generation requests. It listens on a configurable port, defaulting to 1314 
		unless overridden by the \textit{REFINERY\_GENERATOR\_WS\_PORT} environment variable. 
		
		The class sets up a Jetty server, configures a ServletContextHandler for managing requests and sessions, 
		and integrates WebSocket support through JettyWebSocketServletContainerInitializer.

		The GeneratorServerInitServlet servlet is registered for handling WebSocket communication.
		This basically just registers the GeneratorServerEndpoint.
		Once everything is configured, the server is started to handle incoming requests. 
		This class essentially establishes the server infrastructure for the application.

		\textbf{TODO!!!! A NICE IMAGE ABOUT THE GENERATOR SERVER ARCHITECTURE}

	\section{Containerization}

	\section{Deploying on AWS}

	\section{Challenges during the implementation}
	Resource usage of development, Docker image deduplification, HealthCheck for ALB, AWS ALB and NAT